{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "#Ensemble Learning Assignment Answers\n",
        "\n",
        "## Theoretical Questions\n",
        "\n",
        "1. Can we use Bagging for regression problems?\n",
        "\n",
        "Yes, Bagging can be used for regression problems. It works by training multiple base regressors (e.g., Decision Trees) on different bootstrap samples and averaging their predictions to reduce variance and improve accuracy. This is implemented in scikit-learn’s BaggingClassifierBaggingRegressor.\n",
        "\n",
        "2. What is the difference between multiple model training and single model training?\n",
        "\n",
        "Multiple Model Training: Involves training several models (e.g., in ensemble methods like Bagging or Boosting) and combining their predictions (e.g., by voting or averaging). to reduce variance, improve robustness, and enhance generalization.\n",
        "Single Model Training: Trains a single model (e.g., one Decision Tree or SVM) on the entire dataset. It’s simpler but more prone to overfitting or underfitting, depending on the model complexity and data.\n",
        "\n",
        "3. Explain the concept of feature randomness in Random Forest SVM?\n",
        "\n",
        "Feature randomness in Random Forest refers to selecting a random subset of features at each node split during tree construction. Unlike a single Decision Tree, which considers all features for the best split, Random Forest limits the feature set to increase diversity among trees, reduce correlation, and improve generalization. This is controlled by parameters like max_features in scikit-learn.\n",
        "\n",
        "4. What is OOB (Out-of-Bag) Score?\n",
        "\n",
        "The Out-of-Bag (OOB) Score is an estimate of a Random Forest’s performance using samples not included in the bootstrap sample for each tree. Since Bagging uses bootstrap sampling, about 1/3 of the data is left out (OOB samples) for each tree. The OOB score aggregates predictions from trees where a sample was OOB, providing a validation metric without needing a separate test set.\n",
        "\n",
        "5. How can you measure the importance of features in a Random Forest model?\n",
        "\n",
        "Feature importance in Random Forest is measured by:\n",
        "\n",
        "Mean Decrease in Impurity: Sum the reduction in impurity (e.g., Gini or Entropy) caused by splits on a feature across all trees, normalized by the number of trees.\n",
        "Mean Decrease in Accuracy: Permute a feature’s values and measure the drop in OOB accuracy; higher drop indicates higher importance.In scikit-learn, feature_importances_ provides impurity-based importance scores.\n",
        "\n",
        "6. Explain the working principle of a Bagging Classifier.\n",
        "\n",
        "A Bagging Classifier works by:\n",
        "\n",
        "Creating multiple bootstrap samples (random subsets with replacement) from the training data.\n",
        "Training a base classifier (e.g., Decision Tree) on each bootstrap sample independently.\n",
        "Aggregating predictions from all classifiers via majority voting for classification.This reduces variance, improves stability, and mitigates overfitting by averaging out errors from individual models.\n",
        "\n",
        "7. How do you evaluate a Bagging Classifier's performance?\n",
        "\n",
        "A Bagging Classifier’s performance is evaluated using:\n",
        "\n",
        "Accuracy: Proportion of correct predictions on a test set.\n",
        "Precision, Recall, F1-Score: For imbalanced datasets or specific class focus.\n",
        "ROC-AUC: For probabilistic predictions or binary classification.\n",
        "Cross-Validation: To assess generalization across data splits.\n",
        "Confusion Matrix: To analyze misclassifications.Use scikit-learn’s accuracy_score, classification_report, or cross_val_score for these metrics.\n",
        "\n",
        "8. How does a Bagging Regressor work?\n",
        "\n",
        "A Bagging Regressor works by:\n",
        "\n",
        "Generating multiple bootstrap samples from the training data.\n",
        "Training a base regressor (e.g., Decision Tree) on each sample.\n",
        "Aggregating predictions by averaging the outputs of all regressors.This reduces variance, smooths predictions, and improves robustness compared to a single regressor.\n",
        "\n",
        "9. What is the main advantage of ensemble techniques?\n",
        "\n",
        "The main advantage of ensemble techniques is improved predictive performance through combining multiple models, reducing variance (Bagging), bias (Boosting), or both (Stacking). This leads to better generalization, robustness to noise, and higher accuracy than single models.\n",
        "\n",
        "10. What is the main challenge of ensemble methods?\n",
        "\n",
        "The main challenge is computational complexity. Ensemble methods require training multiple models, increasing time and resource demands. They can also be harder to interpret (e.g., Random Forest vs. a single Decision Tree) and may require careful tuning to avoid overfitting or underfitting.\n",
        "\n",
        "11. Explain the key idea behind ensemble techniques.\n",
        "\n",
        "The key idea is to combine predictions from multiple models to achieve better performance than any single model. By leveraging diversity (different models, data subsets, or features), ensembles reduce errors through averaging (Bagging), sequential improvement (Boosting), or stacking, exploiting the “wisdom of the crowd.”\n",
        "\n",
        "12. What is a Random Forest Classifier?\n",
        "\n",
        "A Random Forest Classifier is an ensemble method that combines multiple Decision Trees trained on bootstrap samples of the data, with random feature subsets at each split. Predictions are made by majority voting across trees, reducing overfitting and improving accuracy compared to a single Decision Tree.\n",
        "\n",
        "13. What are the main types of ensemble techniques?\n",
        "\n",
        "Bagging: Trains models in parallel on bootstrap samples (e.g., Random Forest).\n",
        "Boosting: Trains models sequentially, focusing on errors of previous models (e.g., AdaBoost, Gradient Boosting).\n",
        "Stacking: Combines predictions from multiple models using a meta-learner.\n",
        "Voting: Aggregates predictions via majority voting (classification) or averaging (regression).\n",
        "\n",
        "14. What is ensemble learning in machine learning?\n",
        "\n",
        "Ensemble learning is a machine learning approach that combines predictions from multiple models to improve accuracy, robustness, and generalization. It leverages diverse models or data subsets to reduce bias, variance, or both, outperforming individual models.\n",
        "\n",
        "15. When should we avoid using ensemble methods?\n",
        "\n",
        "Avoid ensemble methods when:\n",
        "\n",
        "Computational resources are limited, as they are resource-intensive.\n",
        "Interpretability is critical, as ensembles are less transparent than single models.\n",
        "Data is insufficient, as ensembles may overfit small datasets.\n",
        "Problem is simple, where a single model (e.g., linear regression) suffices.\n",
        "Real-time predictions are needed, due to higher inference time.\n",
        "\n",
        "16. How does Bagging help in reducing overfitting?\n",
        "\n",
        "Bagging reduces overfitting by:\n",
        "\n",
        "Training models on different bootstrap samples, introducing diversity and reducing reliance on specific data points.\n",
        "Averaging predictions (regression) or voting (classification), which smooths out noise and errors from individual models.\n",
        "Lowering variance, as the ensemble is less sensitive to outliers or fluctuations in the training data.\n",
        "\n",
        "17. Why is Random Forest better than a single Decision Tree?\n",
        "\n",
        "Random Forest is better because:\n",
        "\n",
        "Reduces Overfitting: Combines multiple trees, averaging out individual errors.\n",
        "Increases Diversity: Uses bootstrap sampling and feature randomness, making trees less correlated.\n",
        "Improves Accuracy: Aggregates predictions for more robust results.\n",
        "Handles Noise: Less sensitive to outliers or irrelevant features.\n",
        "Feature Importance: Provides insights into feature contributions.\n",
        "\n",
        "18. What is the role of bootstrap sampling in Bagging?\n",
        "\n",
        "Bootstrap sampling creates random subsets of the training data by sampling with replacement, typically of the same size as the original dataset. In Bagging, it:\n",
        "\n",
        "Generates diverse training sets for each base model.\n",
        "Reduces variance by ensuring models are trained on varied data.\n",
        "Enables OOB evaluation by leaving out unsampled data.\n",
        "\n",
        "19. What are some real-world applications of ensemble techniques?\n",
        "\n",
        "Finance: Credit risk assessment, fraud detection.\n",
        "Healthcare: Disease diagnosis, patient outcome prediction.\n",
        "Marketing: Customer segmentation, churn prediction.\n",
        "Image Recognition: Object detection, facial recognition.\n",
        "Natural Language Processing: Sentiment analysis, text classification.\n",
        "Recommendation Systems: Personalized product suggestions.\n",
        "\n",
        "20. What is the difference between Bagging and Boosting?\n",
        "\n",
        "Bagging:\n",
        "Trains models in parallel on bootstrap samples.\n",
        "Reduces variance by averaging or voting.\n",
        "Models are independent (e.g., Random Forest).\n",
        "Less prone to overfitting.\n",
        "\n",
        "\n",
        "Boosting:\n",
        "Trains models sequentially, focusing on errors of previous models.\n",
        "Reduces bias and variance by weighting misclassified samples.\n",
        "Models are dependent (e.g., Gradient Boosting, AdaBoost).\n",
        "More prone to overfitting if not tuned properly.\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "__BTErAi9doB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#Practical Questions\n",
        "\n",
        "#21. Train a Bagging Classifier using Decision Trees on a sample dataset and print model accuracy.\n",
        "from sklearn.datasets import load_iris\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Iris dataset\n",
        "iris = load_iris()\n",
        "X, y = iris.data, iris.target\n",
        "\n",
        "# Split into training (70%) and testing (30%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Initialize and train Bagging Classifier with Decision Trees\n",
        "clf = BaggingClassifier(estimator=DecisionTreeClassifier(random_state=42),\n",
        "                        n_estimators=10, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict on test set\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate and print accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Bagging Classifier Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SBX8Z6kp-WqG",
        "outputId": "e985c1e9-454c-40d5-b968-e03a68efe4fc"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier Accuracy: 1.0000\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#22. Train a Bagging Regressor using Decision Trees and evaluate using Mean Squared Error (MSE)\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load California Housing dataset\n",
        "housing = fetch_california_housing()\n",
        "X, y = housing.data, housing.target\n",
        "\n",
        "# Split into training (70%) and testing (30%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Bagging Regressor with Decision Trees\n",
        "reg = BaggingRegressor(estimator=DecisionTreeRegressor(random_state=42),\n",
        "                       n_estimators=10, random_state=42)\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate MSE\n",
        "y_pred = reg.predict(X_test)\n",
        "mse = mean_squared_error(y_test, y_pred)\n",
        "print(f\"Bagging Regressor MSE: {mse:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W6zhuG-z_dLd",
        "outputId": "bfe9a0e5-2c5a-423f-dc4a-ef65333cc2cc"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Regressor MSE: 0.2862\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#23. Train a Random Forest Classifier on the Breast Cancer dataset and print feature importance scores\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Load Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split into training (70%) and testing (30%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Print feature importance scores\n",
        "print(\"Feature Importance Scores:\")\n",
        "for feature, importance in zip(data.feature_names, clf.feature_importances_):\n",
        "    print(f\"{feature}: {importance:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5wazdpMC91Sf",
        "outputId": "bfafa42d-81f5-445c-e154-22a95dc6e085"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importance Scores:\n",
            "mean radius: 0.0323\n",
            "mean texture: 0.0111\n",
            "mean perimeter: 0.0601\n",
            "mean area: 0.0538\n",
            "mean smoothness: 0.0062\n",
            "mean compactness: 0.0092\n",
            "mean concavity: 0.0806\n",
            "mean concave points: 0.1419\n",
            "mean symmetry: 0.0033\n",
            "mean fractal dimension: 0.0031\n",
            "radius error: 0.0164\n",
            "texture error: 0.0032\n",
            "perimeter error: 0.0118\n",
            "area error: 0.0295\n",
            "smoothness error: 0.0059\n",
            "compactness error: 0.0046\n",
            "concavity error: 0.0058\n",
            "concave points error: 0.0034\n",
            "symmetry error: 0.0040\n",
            "fractal dimension error: 0.0071\n",
            "worst radius: 0.0780\n",
            "worst texture: 0.0188\n",
            "worst perimeter: 0.0743\n",
            "worst area: 0.1182\n",
            "worst smoothness: 0.0118\n",
            "worst compactness: 0.0175\n",
            "worst concavity: 0.0411\n",
            "worst concave points: 0.1271\n",
            "worst symmetry: 0.0129\n",
            "worst fractal dimension: 0.0069\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#24. Train a Random Forest Regressor and compare its performance with a single Decision Tree\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load California Housing dataset\n",
        "housing = fetch_california_housing()\n",
        "X, y = housing.data, housing.target\n",
        "\n",
        "# Split into training (70%) and testing (30%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Random Forest Regressor\n",
        "rf_reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "rf_reg.fit(X_train, y_train)\n",
        "y_pred_rf = rf_reg.predict(X_test)\n",
        "mse_rf = mean_squared_error(y_test, y_pred_rf)\n",
        "\n",
        "# Train single Decision Tree Regressor\n",
        "dt_reg = DecisionTreeRegressor(random_state=42)\n",
        "dt_reg.fit(X_train, y_train)\n",
        "y_pred_dt = dt_reg.predict(X_test)\n",
        "mse_dt = mean_squared_error(y_test, y_pred_dt)\n",
        "\n",
        "# Print MSE for both models\n",
        "print(f\"Random Forest Regressor MSE: {mse_rf:.4f}\")\n",
        "print(f\"Decision Tree Regressor MSE: {mse_dt:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5Wbq_6Kr98V0",
        "outputId": "78b0d699-a03b-4768-94eb-f77b30bd1967"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest Regressor MSE: 0.2565\n",
            "Decision Tree Regressor MSE: 0.5280\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#25. Compute the Out-of-Bag (OOB) Score for a Random Forest Classifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "# Load Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split into training (70%) and testing (30%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Random Forest Classifier with OOB score\n",
        "clf = RandomForestClassifier(n_estimators=100, oob_score=True, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Print OOB score\n",
        "print(f\"Out-of-Bag Score: {clf.oob_score_:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Wzxth1TT-DgK",
        "outputId": "f01b7fff-2352-46ac-c48a-8f3c5c52b4e2"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Out-of-Bag Score: 0.9548\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#26. Train a Bagging Classifier using SVM as a base estimator and print accuracy\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split into training (70%) and testing (30%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Bagging Classifier with SVM\n",
        "clf = BaggingClassifier(estimator=SVC(kernel='linear', random_state=42),\n",
        "                        n_estimators=10, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate accuracy\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Bagging Classifier (SVM) Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OrxZTFpy-Jhu",
        "outputId": "1e12e531-7392-4966-f68d-a54b72884a60"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier (SVM) Accuracy: 0.9591\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#27. Train a Random Forest Classifier with different numbers of trees and compare accuracy\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split into training (70%) and testing (30%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Random Forest with different numbers of trees\n",
        "n_estimators = [10, 50, 100]\n",
        "for n in n_estimators:\n",
        "    clf = RandomForestClassifier(n_estimators=n, random_state=42)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy with {n} trees: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yjRhpev0-Org",
        "outputId": "c6913156-22c3-4445-bfc7-b5126758e164"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with 10 trees: 0.9649\n",
            "Accuracy with 50 trees: 0.9708\n",
            "Accuracy with 100 trees: 0.9708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#28. Train a Bagging Classifier using Logistic Regression as a base estimator and print AUC score\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Load Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split into training (70%) and testing (30%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Bagging Classifier with Logistic Regression\n",
        "clf = BaggingClassifier(estimator=LogisticRegression(max_iter=1000, random_state=42),\n",
        "                        n_estimators=10, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities and compute AUC score\n",
        "y_prob = clf.predict_proba(X_test)[:, 1]\n",
        "auc = roc_auc_score(y_test, y_prob)\n",
        "print(f\"Bagging Classifier (Logistic Regression) AUC: {auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "97biBRME-UGK",
        "outputId": "d624bfe3-043f-43c2-b986-9d70b72ccb64"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier (Logistic Regression) AUC: 0.9978\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#29. Train a Random Forest Regressor and analyze feature importance scores\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "\n",
        "# Load California Housing dataset\n",
        "housing = fetch_california_housing()\n",
        "X, y = housing.data, housing.target\n",
        "\n",
        "# Split into training (70%) and testing (30%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Random Forest Regressor\n",
        "reg = RandomForestRegressor(n_estimators=100, random_state=42)\n",
        "reg.fit(X_train, y_train)\n",
        "\n",
        "# Print feature importance scores\n",
        "print(\"Feature Importance Scores:\")\n",
        "for feature, importance in zip(housing.feature_names, reg.feature_importances_):\n",
        "    print(f\"{feature}: {importance:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R6_pgqRM-ZZZ",
        "outputId": "d88b4d2a-cd07-482f-87c7-e44091a00214"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Feature Importance Scores:\n",
            "MedInc: 0.5260\n",
            "HouseAge: 0.0547\n",
            "AveRooms: 0.0472\n",
            "AveBedrms: 0.0300\n",
            "Population: 0.0317\n",
            "AveOccup: 0.1382\n",
            "Latitude: 0.0861\n",
            "Longitude: 0.0861\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#30. Train an ensemble model using both Bagging and Random Forest and compare accuracy\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier, RandomForestClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split into training (70%) and testing (30%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Bagging Classifier\n",
        "bagging_clf = BaggingClassifier(estimator=DecisionTreeClassifier(random_state=42),\n",
        "                                n_estimators=100, random_state=42)\n",
        "bagging_clf.fit(X_train, y_train)\n",
        "y_pred_bagging = bagging_clf.predict(X_test)\n",
        "accuracy_bagging = accuracy_score(y_test, y_pred_bagging)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "rf_clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "rf_clf.fit(X_train, y_train)\n",
        "y_pred_rf = rf_clf.predict(X_test)\n",
        "accuracy_rf = accuracy_score(y_test, y_pred_rf)\n",
        "\n",
        "# Print accuracies\n",
        "print(f\"Bagging Classifier Accuracy: {accuracy_bagging:.4f}\")\n",
        "print(f\"Random Forest Classifier Accuracy: {accuracy_rf:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "erb5LKFJ-fG1",
        "outputId": "5f7fa3f1-c40c-41a0-a80e-7d5ec101420d"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier Accuracy: 0.9591\n",
            "Random Forest Classifier Accuracy: 0.9708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#31. Train a Random Forest Classifier and tune hyperparameters using GridSearchCV\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split, GridSearchCV\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split into training (70%) and testing (30%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {'n_estimators': [50, 100], 'max_depth': [None, 10], 'min_samples_split': [2, 5]}\n",
        "\n",
        "# Train Random Forest with GridSearchCV\n",
        "clf = RandomForestClassifier(random_state=42)\n",
        "grid_search = GridSearchCV(clf, param_grid, cv=5, scoring='accuracy')\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print best parameters and accuracy\n",
        "print(f\"Best Parameters: {grid_search.best_params_}\")\n",
        "y_pred = grid_search.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Accuracy with Best Parameters: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E46iuH3I-q7z",
        "outputId": "7a6d35b1-8acc-4743-c6e6-28b7a1843199"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'max_depth': None, 'min_samples_split': 5, 'n_estimators': 100}\n",
            "Accuracy with Best Parameters: 0.9591\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#32. Train a Bagging Regressor with different numbers of base estimators and compare performance\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load California Housing dataset\n",
        "housing = fetch_california_housing()\n",
        "X, y = housing.data, housing.target\n",
        "\n",
        "# Split into training (70%) and testing (30%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Bagging Regressor with different numbers of estimators\n",
        "n_estimators = [10, 50, 100]\n",
        "for n in n_estimators:\n",
        "    reg = BaggingRegressor(estimator=DecisionTreeRegressor(random_state=42),\n",
        "                           n_estimators=n, random_state=42)\n",
        "    reg.fit(X_train, y_train)\n",
        "    y_pred = reg.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(f\"MSE with {n} estimators: {mse:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NcwZnFKX-w_7",
        "outputId": "25945503-a309-4a16-c25a-2342fc3ebed7"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE with 10 estimators: 0.2862\n",
            "MSE with 50 estimators: 0.2579\n",
            "MSE with 100 estimators: 0.2568\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#33. Train a Random Forest Classifier and analyze misclassified samples\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "\n",
        "# Load Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split into training (70%) and testing (30%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and identify misclassified samples\n",
        "y_pred = clf.predict(X_test)\n",
        "misclassified = np.where(y_test != y_pred)[0]\n",
        "print(f\"Number of Misclassified Samples: {len(misclassified)}\")\n",
        "print(\"Misclassified Sample Indices:\", misclassified)\n",
        "for idx in misclassified:\n",
        "    print(f\"Sample {idx}: True={data.target_names[y_test[idx]]}, Predicted={data.target_names[y_pred[idx]]}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6_QrRXjy-2lo",
        "outputId": "c099f4b6-f402-4838-b2c7-a838769092e7"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Number of Misclassified Samples: 5\n",
            "Misclassified Sample Indices: [  8  20  77  82 164]\n",
            "Sample 8: True=benign, Predicted=malignant\n",
            "Sample 20: True=malignant, Predicted=benign\n",
            "Sample 77: True=malignant, Predicted=benign\n",
            "Sample 82: True=malignant, Predicted=benign\n",
            "Sample 164: True=malignant, Predicted=benign\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#34. Train a Bagging Classifier and compare its performance with a single Decision Tree Classifier\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split into training (70%) and testing (30%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Bagging Classifier\n",
        "bagging_clf = BaggingClassifier(estimator=DecisionTreeClassifier(random_state=42),\n",
        "                                n_estimators=100, random_state=42)\n",
        "bagging_clf.fit(X_train, y_train)\n",
        "y_pred_bagging = bagging_clf.predict(X_test)\n",
        "accuracy_bagging = accuracy_score(y_test, y_pred_bagging)\n",
        "\n",
        "# Train single Decision Tree Classifier\n",
        "dt_clf = DecisionTreeClassifier(random_state=42)\n",
        "dt_clf.fit(X_train, y_train)\n",
        "y_pred_dt = dt_clf.predict(X_test)\n",
        "accuracy_dt = accuracy_score(y_test, y_pred_dt)\n",
        "\n",
        "# Print accuracies\n",
        "print(f\"Bagging Classifier Accuracy: {accuracy_bagging:.4f}\")\n",
        "print(f\"Decision Tree Classifier Accuracy: {accuracy_dt:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58EIXzpN-8Rf",
        "outputId": "c35a3437-54f4-45c3-e9e4-d2759494e591"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Classifier Accuracy: 0.9591\n",
            "Decision Tree Classifier Accuracy: 0.9415\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#35. Train a Random Forest Classifier and visualize the confusion matrix\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import confusion_matrix\n",
        "import seaborn as sns\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split into training (70%) and testing (30%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and compute confusion matrix\n",
        "y_pred = clf.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "\n",
        "# Visualize confusion matrix\n",
        "sns.heatmap(cm, annot=True, fmt='d', cmap='Blues', xticklabels=data.target_names, yticklabels=data.target_names)\n",
        "plt.xlabel('Predicted')\n",
        "plt.ylabel('Actual')\n",
        "plt.title('Confusion Matrix for Random Forest Classifier')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "wrzUQ09l_BoN",
        "outputId": "da2468ad-6540-420d-e1e4-1e157263b370"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#36. Train a Stacking Classifier using Decision Trees, SVM, and Logistic Regression, and compare accuracy\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import StackingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split into training (70%) and testing (30%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define base estimators\n",
        "estimators = [\n",
        "    ('dt', DecisionTreeClassifier(random_state=42)),\n",
        "    ('svm', SVC(kernel='linear', probability=True, random_state=42)),\n",
        "    ('lr', LogisticRegression(max_iter=1000, random_state=42))\n",
        "]\n",
        "\n",
        "# Train Stacking Classifier\n",
        "clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(), cv=5)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate accuracy\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Stacking Classifier Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "p4EkSA0y_GY4",
        "outputId": "bb5e4521-cae8-46d9-a701-e37436ad598c"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Classifier Accuracy: 0.9766\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:465: ConvergenceWarning: lbfgs failed to converge (status=1):\n",
            "STOP: TOTAL NO. OF ITERATIONS REACHED LIMIT.\n",
            "\n",
            "Increase the number of iterations (max_iter) or scale the data as shown in:\n",
            "    https://scikit-learn.org/stable/modules/preprocessing.html\n",
            "Please also refer to the documentation for alternative solver options:\n",
            "    https://scikit-learn.org/stable/modules/linear_model.html#logistic-regression\n",
            "  n_iter_i = _check_optimize_result(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#37. Train a Random Forest Classifier and print the top 5 most important features\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "import numpy as np\n",
        "\n",
        "# Load Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split into training (70%) and testing (30%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Get top 5 most important features\n",
        "indices = np.argsort(clf.feature_importances_)[::-1][:5]\n",
        "print(\"Top 5 Most Important Features:\")\n",
        "for idx in indices:\n",
        "    print(f\"{data.feature_names[idx]}: {clf.feature_importances_[idx]:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xiARBCWS_Lpu",
        "outputId": "c8a87cba-a277-4798-bdab-4e3f977633b1"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 5 Most Important Features:\n",
            "mean concave points: 0.1419\n",
            "worst concave points: 0.1271\n",
            "worst area: 0.1182\n",
            "mean concavity: 0.0806\n",
            "worst radius: 0.0780\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#38. Train a Bagging Classifier and evaluate performance using Precision, Recall, and F1-score\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import precision_score, recall_score, f1_score\n",
        "\n",
        "# Load Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split into training (70%) and testing (30%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Bagging Classifier\n",
        "clf = BaggingClassifier(estimator=DecisionTreeClassifier(random_state=42),\n",
        "                        n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate metrics\n",
        "y_pred = clf.predict(X_test)\n",
        "precision = precision_score(y_test, y_pred)\n",
        "recall = recall_score(y_test, y_pred)\n",
        "f1 = f1_score(y_test, y_pred)\n",
        "\n",
        "# Print metrics\n",
        "print(f\"Precision: {precision:.4f}\")\n",
        "print(f\"Recall: {recall:.4f}\")\n",
        "print(f\"F1-Score: {f1:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "On3ROEHq_Q-l",
        "outputId": "29ee0a1a-dac0-4022-f571-0626a804ff95"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Precision: 0.9633\n",
            "Recall: 0.9722\n",
            "F1-Score: 0.9677\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#39. Train a Random Forest Classifier and analyze the effect of max_depth on accuracy\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split into training (70%) and testing (30%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Random Forest with different max_depth values\n",
        "depths = [None, 5, 10, 15]\n",
        "for depth in depths:\n",
        "    clf = RandomForestClassifier(n_estimators=100, max_depth=depth, random_state=42)\n",
        "    clf.fit(X_train, y_train)\n",
        "    y_pred = clf.predict(X_test)\n",
        "    accuracy = accuracy_score(y_test, y_pred)\n",
        "    print(f\"Accuracy with max_depth={depth}: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NoKAvoxr_ckG",
        "outputId": "bf7342b0-3464-42ba-88db-421a605a8a2c"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with max_depth=None: 0.9708\n",
            "Accuracy with max_depth=5: 0.9649\n",
            "Accuracy with max_depth=10: 0.9708\n",
            "Accuracy with max_depth=15: 0.9708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#40. Train a Bagging Regressor using different base estimators (DecisionTree and KNeighbors) and compare performance\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.neighbors import KNeighborsRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load California Housing dataset\n",
        "housing = fetch_california_housing()\n",
        "X, y = housing.data, housing.target\n",
        "\n",
        "# Split into training (70%) and testing (30%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Bagging Regressor with Decision Tree\n",
        "reg_dt = BaggingRegressor(estimator=DecisionTreeRegressor(random_state=42),\n",
        "                          n_estimators=10, random_state=42)\n",
        "reg_dt.fit(X_train, y_train)\n",
        "y_pred_dt = reg_dt.predict(X_test)\n",
        "mse_dt = mean_squared_error(y_test, y_pred_dt)\n",
        "\n",
        "# Train Bagging Regressor with KNeighbors\n",
        "reg_knn = BaggingRegressor(estimator=KNeighborsRegressor(),\n",
        "                           n_estimators=10, random_state=42)\n",
        "reg_knn.fit(X_train, y_train)\n",
        "y_pred_knn = reg_knn.predict(X_test)\n",
        "mse_knn = mean_squared_error(y_test, y_pred_knn)\n",
        "\n",
        "# Print MSE for both models\n",
        "print(f\"Bagging Regressor (Decision Tree) MSE: {mse_dt:.4f}\")\n",
        "print(f\"Bagging Regressor (KNeighbors) MSE: {mse_knn:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1L_MVJNf_ieL",
        "outputId": "4d680538-9739-4381-9da2-8e430a685cbd"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Bagging Regressor (Decision Tree) MSE: 0.2862\n",
            "Bagging Regressor (KNeighbors) MSE: 1.1216\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#41. Train a Random Forest Classifier and evaluate its performance using ROC-AUC Score\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Load Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split into training (70%) and testing (30%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities and compute ROC-AUC\n",
        "y_prob = clf.predict_proba(X_test)[:, 1]\n",
        "roc_auc = roc_auc_score(y_test, y_prob)\n",
        "print(f\"Random Forest ROC-AUC Score: {roc_auc:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BZ02CPk3_nLP",
        "outputId": "c991d4c2-32a1-4b57-dfd6-5dfd18264e6f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Random Forest ROC-AUC Score: 0.9968\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#42. Train a Bagging Classifier and evaluate its performance using cross-validation\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "# Load Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Train Bagging Classifier with cross-validation\n",
        "clf = BaggingClassifier(estimator=DecisionTreeClassifier(random_state=42),\n",
        "                        n_estimators=100, random_state=42)\n",
        "scores = cross_val_score(clf, X, y, cv=5, scoring='accuracy')\n",
        "\n",
        "# Print cross-validation scores\n",
        "print(f\"Cross-Validation Scores: {scores}\")\n",
        "print(f\"Average Accuracy: {np.mean(scores):.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1hWX4EbQ_sk4",
        "outputId": "60ad48aa-19de-4725-f368-9d6b82223908"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cross-Validation Scores: [0.89473684 0.93859649 0.99122807 0.96491228 1.        ]\n",
            "Average Accuracy: 0.9579\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#43. Train a Random Forest Classifier and plot the Precision-Recall curve\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import precision_recall_curve, PrecisionRecallDisplay\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "# Load Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split into training (70%) and testing (30%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Random Forest Classifier\n",
        "clf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities and plot Precision-Recall curve\n",
        "y_prob = clf.predict_proba(X_test)[:, 1]\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_prob)\n",
        "disp = PrecisionRecallDisplay(precision=precision, recall=recall)\n",
        "disp.plot()\n",
        "plt.title('Precision-Recall Curve for Random Forest Classifier')\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "kAsSx-PJ_xVW",
        "outputId": "e105788a-b504-4f6b-bd7a-088947a82a9d"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#44. Train a Stacking Classifier with Random Forest and Logistic Regression and compare accuracy\n",
        "from sklearn.datasets import load_breast_cancer\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import StackingClassifier, RandomForestClassifier\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load Breast Cancer dataset\n",
        "data = load_breast_cancer()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split into training (70%) and testing (30%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Define base estimators\n",
        "estimators = [\n",
        "    ('rf', RandomForestClassifier(n_estimators=100, random_state=42)),\n",
        "    ('lr', LogisticRegression(max_iter=1000, random_state=42))\n",
        "]\n",
        "\n",
        "# Train Stacking Classifier\n",
        "clf = StackingClassifier(estimators=estimators, final_estimator=LogisticRegression(random_state=42), cv=5)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate accuracy\n",
        "y_pred = clf.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f\"Stacking Classifier Accuracy: {accuracy:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bjWeTvSN_4GG",
        "outputId": "32d7a923-b11b-4a81-ac8c-d03509b1bb88"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stacking Classifier Accuracy: 0.9708\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#45. Train a Bagging Regressor with different levels of bootstrap samples and compare performance\n",
        "from sklearn.datasets import fetch_california_housing\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.ensemble import BaggingRegressor\n",
        "from sklearn.tree import DecisionTreeRegressor\n",
        "from sklearn.metrics import mean_squared_error\n",
        "\n",
        "# Load California Housing dataset\n",
        "housing = fetch_california_housing()\n",
        "X, y = housing.data, housing.target\n",
        "\n",
        "# Split into training (70%) and testing (30%) sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=42)\n",
        "\n",
        "# Train Bagging Regressor with different max_samples\n",
        "max_samples = [0.5, 0.7, 1.0]\n",
        "for ms in max_samples:\n",
        "    reg = BaggingRegressor(estimator=DecisionTreeRegressor(random_state=42),\n",
        "                           n_estimators=10, max_samples=ms, random_state=42)\n",
        "    reg.fit(X_train, y_train)\n",
        "    y_pred = reg.predict(X_test)\n",
        "    mse = mean_squared_error(y_test, y_pred)\n",
        "    print(f\"MSE with max_samples={ms}: {mse:.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Mafi5n3-__Tv",
        "outputId": "2aeeaa45-8e63-4519-96c7-bac0dd7a3b4c"
      },
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MSE with max_samples=0.5: 0.2969\n",
            "MSE with max_samples=0.7: 0.2952\n",
            "MSE with max_samples=1.0: 0.2862\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lv2u0uw7AGNX"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}